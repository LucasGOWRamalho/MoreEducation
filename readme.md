# MoreEducation 
 Teclado com os Olhos
MoreEducation Ã© um projeto de acessibilidade cujo objetivo Ã© permitir que pessoas com deficiÃªncia possam se comunicar usando apenas o movimento dos olhos. O sistema usa OpenCV e Dlib para capturar e analisar o olhar do usuÃ¡rio, e renderiza um teclado interativo no navegador com Next.js. Ao identificar onde o usuÃ¡rio estÃ¡ olhando, o sistema irÃ¡ simular a digitaÃ§Ã£o.

# ğŸš€ Objetivo
Criar um sistema onde:

- O usuÃ¡rio olha para a tela.

- O sistema detecta a direÃ§Ã£o do olhar com OpenCV + Dlib.

- O usuÃ¡rio pisca para confirmar uma tecla.

- Um teclado virtual Ã© exibido em uma pÃ¡gina Next.js (front/teclado/page.tsx).

- ComunicaÃ§Ã£o entre front-end e back-end ocorre via WebSockets ou API REST.

# ğŸ§  Tecnologias
### ğŸ¯ Back-End (VisÃ£o Computacional)
- Python

- OpenCV

- Dlib (shape predictor 68 pontos)

- WebSocket / FastAPI para comunicaÃ§Ã£o com o front

- MÃ³dulo de detecÃ§Ã£o de piscar e direÃ§Ã£o do olhar

### ğŸ’» Front-End
- Next.js (React)

- TypeScript

- Teclado virtual responsivo (dividido em seÃ§Ãµes por Ã¡rea da tela)

- ComunicaÃ§Ã£o com back-end via WebSocket

# ğŸ—ï¸ Arquitetura

### ğŸ“ projeto-raiz
â”œâ”€â”€ front                  
â”‚       â””â”€â”€ teclado
|               |
â”‚               â””â”€â”€ page.tsx        
â”œâ”€â”€ backend
â”‚   â””â”€â”€ main.py            
â”‚   â””â”€â”€ gaze_tracker.py     
â”œâ”€â”€ shape_predictor_68.dat 
â”œâ”€â”€ README.md
ğŸ”® Planejamento: PrÃ³ximos Passos



### âœ… Etapa 1: Back-End com OpenCV
- Configurar main.py para capturar rosto e olhos âœ…

- Modularizar detecÃ§Ã£o do olhar (gaze direction)

- Detectar em qual direÃ§Ã£o o usuÃ¡rio estÃ¡ olhando (esquerda, centro, direita)

- Detectar piscadas (confirmaÃ§Ã£o de tecla)

- Criar comunicaÃ§Ã£o WebSocket ou API para enviar resultado para o front

### âŒ¨ï¸ Etapa 2: Front-End com Teclado Virtual
- Criar layout do teclado na pÃ¡gina front/teclado/page.tsx

- Dividir tela em zonas correspondentes aos blocos do teclado

- Receber dados do back-end (posiÃ§Ã£o do olhar) e destacar zona da tela

- Simular digitaÃ§Ã£o com piscar (confirmaÃ§Ã£o)

### ğŸ”— Etapa 3: IntegraÃ§Ã£o
- Conectar front e back usando WebSocket (ou REST para testes iniciais)

- Realizar testes de usabilidade com cursor visual (foco) e piscadas

### ğŸŒ Etapa 4: Acessibilidade Real
- Melhorar acurÃ¡cia da detecÃ§Ã£o

- Adicionar configuraÃ§Ãµes de acessibilidade (tamanho da fonte, contraste, etc.)

- InternacionalizaÃ§Ã£o (i18n)

- Feedback auditivo (opcional)

## ğŸ“¸ Imagem Futuro
- O usuÃ¡rio poderÃ¡:

- Acessar o site via webcam

- Navegar no teclado com os olhos

- Piscar para selecionar letras e formar frases

- Enviar mensagens com autonomia

